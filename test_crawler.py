"""
YouTube í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ ë° ìžë§‰ ì—¬ë¶€ í™•ì¸ ê¸°ëŠ¥ì„ í¬í•¨í•©ë‹ˆë‹¤.
"""

import os
import requests
from datetime import datetime, timedelta
import json
from typing import List, Dict, Optional
from youtube_transcript_api import YouTubeTranscriptApi

class SimpleYouTubeCrawler:
    """YouTube í¬ë¡¤ëŸ¬ (í‚¤ì›Œë“œ ê²€ìƒ‰, ì´ë©”ì¼ ì¶”ì¶œ, ìžë§‰ í™•ì¸ ì§€ì›)"""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://www.googleapis.com/youtube/v3"
        
    def extract_email(self, text: str) -> Optional[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ì´ë©”ì¼ ì£¼ì†Œ ì¶”ì¶œ"""
        if not text: return "N/A"
        import re
        email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}'
        match = re.search(email_pattern, text)
        return match.group(0) if match else "N/A"

    def check_subtitle_availability(self, video_id: str) -> bool:
        """ì˜ìƒì— í•œê¸€ ìžë§‰ì´ ìžˆëŠ”ì§€ í™•ì¸"""
        try:
            transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)
            # í•œêµ­ì–´ ìžë§‰ì´ ìžˆëŠ”ì§€ ìš°ì„  í™•ì¸
            try:
                transcript_list.find_transcript(['ko'])
                return True
            except:
                # í•œêµ­ì–´ ìžë§‰ì´ ì—†ìœ¼ë©´ ìˆ˜ë™/ìžë™ ìƒì„±ëœ ìžë§‰ ì¤‘ í•˜ë‚˜ë¼ë„ ìžˆëŠ”ì§€ í™•ì¸
                return any(t.language_code == 'ko' or t.is_generated for t in transcript_list)
        except:
            return False

    def get_transcript(self, video_id: str) -> Optional[str]:
        """ì˜ìƒ ìžë§‰ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        try:
            # í•œêµ­ì–´ ìžë§‰ ì‹œë„ -> ì‹¤íŒ¨ì‹œ ì˜ì–´ ìžë§‰ -> ì‹¤íŒ¨ì‹œ ì²« ë²ˆì§¸ ìžë§‰
            try:
                transcript = YouTubeTranscriptApi.fetch_transcript(video_id, languages=['ko'])
            except:
                try:
                    transcript = YouTubeTranscriptApi.fetch_transcript(video_id, languages=['en'])
                except:
                    transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)
                    transcript = transcript_list.find_transcript(['ko', 'en']).fetch()
            
            return " ".join([t['text'] for t in transcript])
        except:
            return None

    def get_channel_info(self, channel_id: str) -> Optional[Dict]:
        """ì±„ë„ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
        url = f"{self.base_url}/channels"
        params = {
            'part': 'snippet,statistics',
            'id': channel_id,
            'key': self.api_key
        }
        
        try:
            response = requests.get(url, params=params)
            response.raise_for_status()
            data = response.json()
            
            if 'items' in data and len(data['items']) > 0:
                item = data['items'][0]
                snippet = item['snippet']
                stats = item['statistics']
                description = snippet.get('description', '')
                
                return {
                    'subscriber_count': stats.get('subscriberCount', '0'),
                    'email': self.extract_email(description)
                }
            return None
        except:
            return None

    def get_video_statistics(self, video_id: str) -> Optional[Dict]:
        """ì˜ìƒ í†µê³„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
        url = f"{self.base_url}/videos"
        params = {
            'part': 'statistics',
            'id': video_id,
            'key': self.api_key
        }
        
        try:
            response = requests.get(url, params=params)
            response.raise_for_status()
            data = response.json()
            
            if 'items' in data and len(data['items']) > 0:
                stats = data['items'][0]['statistics']
                return {
                    'view_count': stats.get('viewCount', '0')
                }
            return None
        except:
            return None
    
    def search_videos_by_keyword(self, keyword: str, max_results: int = 5, days_back: int = 7) -> List[Dict]:
        """í‚¤ì›Œë“œ ê²€ìƒ‰ ë° ìžë§‰ ì—¬ë¶€ í¬í•¨ ìˆ˜ì§‘"""
        print(f"ðŸ”Ž í‚¤ì›Œë“œ ê²€ìƒ‰ ì¤‘: {keyword}")
        
        url = f"{self.base_url}/search"
        after_date = (datetime.now() - timedelta(days=days_back)).isoformat() + 'Z'
        
        params = {
            'part': 'snippet',
            'q': keyword,
            'type': 'video',
            'order': 'relevance',
            'maxResults': max_results,
            'key': self.api_key,
            'publishedAfter': after_date
        }
        
        try:
            response = requests.get(url, params=params)
            response.raise_for_status()
            data = response.json()
            
            videos = []
            if 'items' in data:
                for item in data['items']:
                    video_id = item['id']['videoId']
                    channel_id = item['snippet']['channelId']
                    
                    v_stats = self.get_video_statistics(video_id)
                    c_info = self.get_channel_info(channel_id)
                    has_subtitle = self.check_subtitle_availability(video_id)
                    
                    video_info = {
                        'video_id': video_id,
                        'title': item['snippet']['title'],
                        'description': item['snippet']['description'],
                        'published_at': item['snippet']['publishedAt'],
                        'video_url': f"https://www.youtube.com/watch?v={video_id}",
                        'view_count': v_stats.get('view_count', '0') if v_stats else '0',
                        'channel_title': item['snippet']['channelTitle'],
                        'channel_id': channel_id,
                        'subscriber_count': c_info.get('subscriber_count', '0') if c_info else '0',
                        'email': c_info.get('email', 'N/A') if c_info else 'N/A',
                        'has_subtitle': has_subtitle
                    }
                    videos.append(video_info)
            return videos
        except Exception as e:
            print(f"âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    def test_crawl(self, keywords: List[str], max_results: int = 5, days_back: int = 7) -> Dict:
        results = {
            'crawl_time': datetime.now().isoformat(),
            'total_videos': 0,
            'channels': {}
        }
        
        for keyword in keywords:
            if not keyword: continue
            videos = self.search_videos_by_keyword(keyword, max_results=max_results, days_back=days_back)
            if videos:
                results['channels'][keyword] = {
                    'status': 'success',
                    'videos': videos,
                    'video_count': len(videos)
                }
                results['total_videos'] += len(videos)
        
        return results
    
    def save_results(self, results: Dict):
        os.makedirs('data', exist_ok=True)
        filename = f"data/test_crawl_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
